---
title: "DATA 624 - Homework 5"
author: "OMER OZEREN"
output:
  html_document:
    highlight: tango
    theme: journal
    toc: yes
    toc_depth: 5
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '5'
---

Do exercises 7.1, 7.5,7.6, 7.7, 7.8 and 7.9  in Hyndman.  Please submit both the link to your Rpubs and the .rmd file.

```{r echo=FALSE, include=FALSE}
library(mlbench)
library(corrplot)
library(mice)
library(ggplot2)
library(dplyr)
library(GGally)
library(fpp2)
library(VIM)
library(mice)
library(kableExtra)
library(seasonal)
```

## Question 7.1



### a. 

Use the ses() function in R to find the optimal values of apha and sigma, and generate forecasts for the next four months.

```{r}
model_fit <- ses(pigs, h = 4) # the next four months
summary(model_fit)
```

**By using 'ses()' function,the optimal values for alpha of `r model_fit$model$par[1]` and a sigma of `r model_fit$model$par[2]`.**

### b. 

Compute a 95% prediction interval for the first forecast using  $\hat{y}\pm1.96s$  where  s is the standard deviation of the residuals. Compare your interval with the interval produced by R.

```{r}
# First start with predicting the first forecast, and the standard deviation
model_fit.stdev <- sd(model_fit$residuals)
model_fit.forecast_1 <- model_fit$mean[1]
# generate the prediction interval
model_fit.pred95 <- c(
  model_fit.Lower.95 = model_fit.forecast_1 - 1.96 * model_fit.stdev, 
  model_fit.Upper.95 = model_fit.forecast_1 + 1.96 * model_fit.stdev
)
# 95% prediction interval 
model_fit.pred95
```

### c. 

Compare your interval with the interval produced by R.

**Prediction interval using residuals :** `r model_fit.pred95`

**Prediction interval of R :** `r round(model_fit$lower[1, '95%'],2)` ,`r round(model_fit$upper[1, '95%'],2)`

**They are slightly different**

## Question 7.5

Data set books contains the daily sales of paperback and hardcover books at the same store. The task is to forecast the next four days' sales for paperback and hardcover books.

### a.

Plot the series and discuss the main features of the data.

```{r}
autoplot(books) +
  ggtitle('Daily sales of paper and hardcover books sale')
```

The dataset presents the daily sales of paperback and hardcover books over a period of 30 days.Since, there is only 30 days of data so we can't make  TRUE conclusion on seasonality or weekly effects.However, by just looking given dataset paperback book sale shows seasonal pattern where book salepeak by end of the week and it decreases in mid week.In addition to that, Paperback and Hardcover sales are uptrend but hardcover sales mean is higher than paperback sales.

### b. 

Use the `ses()` function to forecast each series, and plot the forecasts.
```{r}
model_ses_paperback <- ses(books[, 1], h = 4)
autoplot(model_ses_paperback, PI=FALSE) +
  ylab("paperback Book Sales ")
```

```{r}
model_ses_hardcover <- ses(books[, 2], h = 4)
autoplot(model_ses_hardcover, PI=FALSE) +
  ylab("hardback Book Sales")
```

### c.

Compute the RMSE values for the training data in each case.
  

```{r}
# Hardcover RMSE
hardcover_RMSE<- sqrt(model_ses_hardcover$model$mse)
# Paperback RMSE
paperback_RMSE <- sqrt(model_ses_paperback$model$mse)
combined_books_RMSE<- c(Hardcover=hardcover_RMSE,
                PaperBack=paperback_RMSE)
# RMSE for papaerback and hardcover
combined_books_RMSE
```

By using SES model, the hardcover RMSE is `r hardcover_RMSE` and the paperback RMSE is `r paperback_RMSE`.

## Question 7.6

We will continue with the daily sales of paperback and hardcover books in data set `books`.

### a. 

Apply Holt's linear method to the `paperback` and `hardback` series and compute four-day forecasts in each case.

```{r}
model_holt_paperback <- holt(books[, 1], h = 4) # four days predictions
autoplot(model_holt_paperback) +
  ylab("Paperback Book Sales")
summary(model_holt_paperback)
```

```{r}
model_holt_hardcover <- holt(books[, 2], h = 4) # four days predictions
autoplot(model_holt_hardcover) +
  ylab("Hardcover Book Sales")
summary(model_holt_hardcover) # if I'd like to see summary
```

### b. 

Compare the RMSE measures of Holt's method for the two series to those of simple exponential smoothing in the previous question. (Remember that Holt's method is using one more parameter than SES.) Discuss the merits of the two forecasting methods for these data sets.

**The RMSE in Holt's method is smaller for both the paperback and hardback.So we can say taht Holt's model does a better job than the SES model.The reason might be is because Holt's model includes a trend component and SES model does not includetrend.**

```{r, echo=FALSE}
data.frame(Type = c('Paperback', 'Hardback'),
           SES = c(accuracy(model_ses_paperback)[2], accuracy(model_ses_hardcover)[2]),
           Holt = c(accuracy(model_holt_paperback)[2], accuracy(model_holt_hardcover)[2])
           ) %>%
  rename(`Holt's Method` = Holt) %>%
  kable() %>%
  kable_styling()
```

### c. 

Compare the forecasts for the two series using both methods. Which do you think is best?

```{r}
# Prediction for Hardcover
rbind(SES=model_ses_hardcover$mean[1:4],
      Holt=model_holt_hardcover$mean[1:4]) %>% t
```

```{r}
# Prediction for Paperback
rbind(SES=model_ses_paperback$mean[1:4],
      Holt=model_holt_paperback$mean[1:4]) %>% t
```

The Holt forecast appears better, The SES method generates straightline forecast, while the Holt forecasting method generates the trend.In addition to that ,The RMSE in Holt's method is smaller for both the paperback and hardback.

### d. 
Calculate a 95% prediction interval for the first forecast for each series, using the RMSE values and assuming normal errors. Compare your intervals with those produced using `ses` and `holt`.

#### Ses Model
Prediction interval of R SES (Papeback) : `r round(model_ses_paperback$lower[1, '95%'],2)` , `r round(model_ses_paperback$upper[1, '95%'],2)`

Prediction interval of R SES (Hardcover) : `r round(model_ses_hardcover$lower[1, '95%'],2)` , `r round(model_ses_hardcover$upper[1, '95%'],2)`

Prediction interval using RMSE SES (Paperback) :  `r round(model_ses_paperback$mean[1] - 1.96 * accuracy(model_ses_paperback)[2],2)`, `r round(model_ses_paperback$mean[1] + 1.96 * accuracy(model_ses_paperback)[2],2)`


Prediction interval using RMSE SES (Hardcover) :  `r round(model_ses_hardcover$mean[1] - 1.96 * accuracy(model_ses_hardcover)[2],2)`, `r round(model_ses_hardcover$mean[1] + 1.96 * accuracy(model_ses_hardcover)[2],2)`


#### Holts model

Prediction interval of R Holt's (Papeback) : `r round(model_holt_paperback$lower[1, '95%'],2)` , `r round(model_holt_paperback$upper[1, '95%'],2)`

Prediction interval of R Holt's (Hardcover) : `r round(model_holt_hardcover$lower[1, '95%'],2)` , `r round(model_holt_hardcover$upper[1, '95%'],2)`

Prediction interval using RMSE Holt's (Paperback) :  `r round(model_holt_paperback$mean[1] - 1.96 * accuracy(model_holt_paperback)[2],2)`, `r round(model_holt_paperback$mean[1] + 1.96 * accuracy(model_holt_paperback)[2],2)`


Prediction interval using RMSE Holt's (Hardcover) :  `r round(model_holt_hardcover$mean[1] - 1.96 * accuracy(model_holt_hardcover)[2],2)`, `r round(model_holt_hardcover$mean[1] + 1.96 * accuracy(model_holt_hardcover)[2],2)`


**They are different but close for both the models (SES and Holt)**

## Question 7.7

For this exercise use data set `eggs`, the price of a dozen eggs in the United States from 1900-1993. Experiment with the various options in the `holt()` function to see how much the forecasts change with damped trend, or with a Box-Cox transformation. Try to develop an intuition of what each argument is doing to the forecasts.

[Hint: use `h=100` when calling `holt()` so you can clearly see the differences between the various options when plotting the forecasts.]

Which model gives the best RMSE?
```{r}
model_holt_eggs <- holt(eggs, h=100)
model_bc_eggs <- holt(eggs, h=100, lambda=TRUE)
model_damped_eggs <- holt(eggs, h=100, damped=TRUE)
model_damped_bc_eggs <- holt(eggs, h=100, damped=TRUE, lambda=TRUE)
model_exponential_eggs <- holt(eggs, h=100, exponential=TRUE)
autoplot(model_holt_eggs) + ggtitle("Holt's Method") 
autoplot(model_damped_eggs) + ggtitle("Damped")
autoplot(model_bc_eggs) + ggtitle("Box-Cox")
autoplot(model_damped_bc_eggs) + ggtitle("Damped & Box-Cox")
autoplot(model_exponential_eggs) + ggtitle("Exponential")
```



```{r}
get_rmse <- function(model){
  accuracy(model)[2]
}
Model_Name <- c("Holt's Linear", 
           "Box-Cox Transformed",
           "Damped",
           "Damped and Box-Cox",
           "Exponential")
RMSE <- c(get_rmse(model_holt_eggs), 
          get_rmse(model_bc_eggs),
          get_rmse(model_damped_eggs),
          get_rmse(model_damped_bc_eggs),
          get_rmse(model_exponential_eggs))
eggs_rmse_df <- data.frame(Model_Name, RMSE) 
eggs_rmse_df %>%
  kable() %>%
  kable_styling()
```

**The minimum RMSE 26.54 occurs when lambda = TRUE which model name is model_damped_eggs**

## Question 7.8

```{r}
#borrowed code from week1 hw to load the aussie retail data
temp_file <- tempfile(fileext = ".xlsx")
download.file(url = "https://github.com/omerozeren/DATA624/raw/master/HMW1/retail.xlsx", 
              destfile = temp_file, 
              mode = "wb", 
              quiet = TRUE)
retaildata <- readxl::read_excel(temp_file,skip=1)
aussie.retail <- ts(retaildata[,"A3349388W"],
  frequency=12, start=c(1982,4))
#run decomp as per the text
x11.decomp <- seas(aussie.retail, x11="")
autoplot(x11.decomp, main = "Aussie Retail - X11 Decomposition" )
```


### a. 

Why is multiplicative seasonality necessary for this series?


The multiplicative seasonality adjustment is really important when the variability in the series is increasing over time.The meaning the effect of the seasonality is added to the trend to get the forecast.

### b. 

Apply Holt-Winters' multiplicative method to the data. Experiment with making the trend damped.

```{r}
model_multiplicative <- hw(aussie.retail, seasonal = "multiplicative")
autoplot(model_multiplicative) + 
  ggtitle("Multiplicative") + 
  ylab("Retail Sales")
summary(model_multiplicative)
model_multiplicative_damped <- hw(aussie.retail, seasonal = "multiplicative", damped = TRUE)
autoplot(model_multiplicative_damped) + 
  ggtitle("Multiplicative & Damped") + 
  ylab("Retail Sales")
summary(model_multiplicative_damped)
```
### c. 

Compare the RMSE of the one-step forecasts from the two methods. Which do you prefer?

```{r}
cat("RMSE of Multiplicative = ", accuracy(model_multiplicative)[2])
```

```{r}
cat("RMSE of Multiplicative & Damped = ", accuracy(model_multiplicative_damped)[2])
```

**The non-damped model is preforming better with lower RMSE.**

d. Check that the residuals from the best method look like white noise.

```{r}
checkresiduals(model_multiplicative)
```

**ADF Test shows that the residuals seems like white noise.In addition to that The residuals are normally distributed with a mean of zero**

### e. 

Now find the test set RMSE, while training the model to the end of 2010. Can you beat the seasonal naive approach from Exercise 8 in Section 3.7?

```{r}
retail_train <- window(aussie.retail, end = c(2010, 12))
retail_test <- window(aussie.retail, start = 2011)
rmse <- function(model){
  accuracy(model, retail_test)[4]
}
Model <- c("Seasonal Naive (Baseline)", 
           "SES",
           "Holt's Method",
           "Damped Holt's Method",
           "Holt-Winters Additive",
           "Holt-Winters Multiplicative",
           "Damped Holt-Winters Additive",
           "Damped Holt-Winters Multiplicative")
RMSE <- c(rmse(snaive(retail_train)), 
          rmse(ses(retail_train)),
          rmse(holt(retail_train)),
          rmse(holt(retail_train, damped = TRUE)),
          rmse(hw(retail_train, seasonal = "additive")),
          rmse(hw(retail_train, seasonal = "multiplicative")),
          rmse(hw(retail_train, seasonal = "additive", damped = TRUE)),
          rmse(hw(retail_train, seasonal = "multiplicative", damped = TRUE)))
rmse_df <- data.frame(Model, RMSE) 
rmse_df %>%
  kable() %>%
  kable_styling()
```
**By comparing all models,I found out `r rmse_df[rmse_df$RMSE == min(rmse_df$RMSE),]$Model` with `r rmse_df[rmse_df$RMSE == min(rmse_df$RMSE),]$RMSE` RMSE preformed the best on the test set.**

## Question 7.9 

For the same retail data, try an STL decomposition applied to the Box-Cox transformed series, followed by ETS on the seasonally adjusted data. How does that compare with your best previous forecasts on the test set?

```{r}
# Train Dta
retail_train <- ts(as.vector(aussie.retail), start=c(1982,4), end=c(2010,12), frequency = 12)
# Get the optimal lambda
lambda <- BoxCox.lambda(retail_train)
# Preform a Box-Cox transformation
bc_retail_train <- BoxCox(retail_train, lambda = lambda)
# Preform the STL decomposition
stl_retail_train <- mstl(bc_retail_train)
## Create a seasonally adjusted series
sa_stl_retail_train <- stl_retail_train[,1] - stl_retail_train[,3]
sa_retail_train <- InvBoxCox(sa_stl_retail_train, lambda = lambda)
# the output
autoplot(retail_train) + autolayer(sa_retail_train)
```

```{r}
ets_retail_train <- forecast(sa_retail_train)
rmse_df %>%
  mutate(Model = as.character(Model)) %>%
  rbind(c("STL Seasonally-Adjusted data", rmse(ets_retail_train))) %>%
  kable() %>%
  kable_styling()
```

**The ETS model error metric RMSE is  worse than the Seasonal Naive model.**
