train.r
bag_model <- train(x = train.p,
y = train.r, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
train.r
bag_model <- train(train.r ~.,
data = train.p, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
log_model <- lm(PH~.,data = train_data)
log_model
train_data$PH
set.seed(123)
training.samples <- df_model_train$PH %>%
createDataPartition(p = 0.8, list = FALSE)
train_data  <- df_model_train[training.samples, ]
test_data <- df_model_train[-training.samples, ]
# Train & Test predictor variables
train_features = df_model_train[training.samples, ] %>% select(-PH)
test_features = df_model_train[-training.samples, ] %>% select(-PH)
# Train & Test response variable (pH)
train_target = df_model_train$PH[training.samples]
test_target = df_model_train$PH[-training.samples]
View(train_features)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(x=train_target ~.,
y = train_target, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
bag_model <- train(x=train_features ~.,
y = train_target, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
# Make predictions
bag_model <- train(x=train_features,
y = train_target, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
marsModel = train(x = train_features,
y = train_target,
method = "earth",
tuneGrid = marsGrid,
trControl = trainControl(method = "cv",
number = 10))
marsGrid = expand.grid(.degree = 1:2,
.nprune = 2:38)
marsModel = train(x = train_features,
y = train_target,
method = "earth",
tuneGrid = marsGrid,
trControl = trainControl(method = "cv",
number = 10))
train_target
train_target<- as.factor(train_target)
train_target
bag_model <- train(x=train_features,
y = train_target, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 25)
df_model_train
set.seed(123)
training.samples <- df_model_train$PH %>%
createDataPartition(p = 0.8, list = FALSE)
train.data  <- df_model_train[training.samples, ]
test.data <- df_model_train[-training.samples, ]
train.data
test.data
control = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train.data$PH, 10), verboseIter = FALSE)
# creating list of models to be tested
algorithmList = c( "earth", "svmRadial", "rpart2", "rf","treebag", "gbm", "cubist", "xgbTree")
#  training selected models on the training data set
set.seed(143)
models = caretList(PH ~ ., data=train.data, trControl=control, methodList=algorithmList)
bag_model <- train(PH ~ .,
data=train.data, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 4)
bag_model <- train(PH ~ .,
data=train.data, method="bag")
aggr(df_train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
imputer<-mice(df_train, method = "pmm", print = FALSE, seed = 143)
df_train_imputed <-complete(imputer)
aggr(df_train_imputed, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
avoid_features = nearZeroVar(df_train_imputed)
df_model_train = df_train_imputed[,-avoid_features]
imputer<-mice(df_eval, method = "pmm", print = FALSE, seed = 143)
df_eval_imputed <-complete(imputer)
avoid_features = nearZeroVar(df_eval_imputed)
df_model_eval = df_eval_imputed[,-avoid_features]
summary(df_model_train)
aggr(df_model_train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
library(tidyverse)
library(kableExtra)
library(xgboost)
library(plyr)
library (e1071)
library(corrplot)
library(ggplot2)
library(tidyr)
library(dplyr)
library(caret)
library(Matrix)
library(writexl)
library(psych)
temp_file <- tempfile(fileext = ".xlsx")
download.file(url = "https://raw.githubusercontent.com/omerozeren/DATA624/master/Project2/StudentEvaluation.xlsx",
destfile = temp_file,
mode = "wb",
quiet = TRUE)
#load xl from temp
df_eval <- data.frame(readxl::read_excel(temp_file,skip=0))
#  Brand.Code to factor
df_eval$Brand.Code = as.factor(df_eval$Brand.Code)
temp_file <- tempfile(fileext = ".xlsx")
download.file(url = "https://raw.githubusercontent.com/omerozeren/DATA624/master/Project2/StudentData.xlsx",
destfile = temp_file,
mode = "wb",
quiet = TRUE)
#load xl from temp
df_train <- data.frame(readxl::read_excel(temp_file,skip=0))
#  Brand.Code to factor
df_train$Brand.Code = as.factor(df_train$Brand.Code)
View(df_train)
aggr(df_train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
imputer<-mice(df_train, method = "pmm", print = FALSE, seed = 143)
df_train_imputed <-complete(imputer)
avoid_features = nearZeroVar(df_train_imputed)
df_model_train = df_train_imputed[,-avoid_features]
aggr(df_model_train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~ .,
data=df_model_train, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 4)
set.seed(123)
training.samples <- df_model_train$PH %>%
createDataPartition(p = 0.8, list = FALSE)
train_data  <- df_model_train[training.samples, ]
test_data <- df_model_train[-training.samples, ]
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~ .,
data=train_data, method="bag",
center = TRUE,
scale = TRUE,
trControl = trcontrol,
tuneLength = 4)
bag_model <- train(PH ~ .,
data=train_data, method="bag",
center = TRUE,
scale = TRUE,
trControl )
bag_model <- train(PH ~ .,
data=train_data, method="bag",
center = TRUE,
scale = TRUE)
aggr(train_data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(df_train), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
View(train_data)
training.samples
log_model <- lm(PH~.,data = train_data)
View(train_data)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~.,
data = train_data, method="bag", bagControl = bagControl,
center = TRUE,
scale = TRUE,
trControl = trainControl("cv", number = 5),
tuneLength = 25)
bag_model
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~.,
data = train_data, method="bag", bagControl = bagControl,
center = TRUE,
scale = TRUE,
trControl = trainControl("cv", number = 5),
tuneLength = 25)
bag_pred <- predict(bag_model, newdata = test_data)
bag_pred
post_rst<-postResample(obs = test_data$PH, pred=bag_pred)
results <- data.frame(t(post_rst)) %>%
mutate(Model = "Bagged Tree Model") %>% rbind(results)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
elas_net_model <- train(PH ~ ., data = train_data, method = "glmnet",
trControl = trcontrol,
tuneLength = 25)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
elas_net_model <- train(PH ~ ., data = train_data, method = "glmnet",
trControl = trcontrol,
tuneLength = 25)
results <- data.frame()
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~.,
data = train_data, method="bag", bagControl = bagControl,
center = TRUE,
scale = TRUE,
trControl = trainControl("cv", number = 5),
tuneLength = 25)
# Make predictions
bag_pred <- predict(bag_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=bag_pred)
results <- data.frame(t(post_rst)) %>%
mutate(Model = "Bagged Tree Model") %>% rbind(results)
View(results)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
elas_net_model <- train(PH ~ ., data = train_data, method = "cubist",
trControl = trcontrol,
tuneLength = 25)
models_test_evaluation <- data.frame()
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
cubist_model <- train(PH ~ ., data = train_data, method = "cubist",
trControl = trcontrol,
tuneLength = 25)
# Make predictions
cubist_pred <- predict(cubist_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=cubist_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "Cubist Model") %>% rbind(models_test_evaluation)
View(models_test_evaluation)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
svm_model <- train(PH ~.,
data=train_data,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 25,
trControl = trcontrol)
svm_pred <- predict(svm_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=svm_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "SVM Model") %>% rbind(models_test_evaluation)
View(models_test_evaluation)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(seed)
rforest <- train(PH ~.,
data = train_data,
method = "ranger",
importance = "permutation",
tuneLength = 10,
trControl = trcontrol
)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
rforest <- train(PH ~.,
data = train_data,
method = "ranger",
importance = "permutation",
tuneLength = 10,
trControl = trcontrol
)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
rforest <- train(PH ~.,
data = train_data,
method = "rf",
tuneLength = 10,
trControl = trcontrol
)
rf_pred <- predict(rforest, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=rf_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "Random Forest Model") %>% rbind(models_test_evaluation)
View(models_test_evaluation)
# trainControl to 10 folds cross validation
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
set.seed(123)
mars_model <- train(PH ~.,
data = train_data,
method = "earth",
tuneLength = 25,
trControl = trcontrol
)
# Make predictions
mars_pred <- predict(mars_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=mars_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "MARS Model") %>% rbind(models_test_evaluation)
plot(mars_model)
plot(bag_model, main='Error Metric "RMSE" Graph')
plot(bag_model, main='Error Metric RMSE Graph')
bag_model
plot(bag_model)
models_test_evaluation %>% dplyr::select(Model, RMSE, Rsquared, MAE)
bwplot(resamples(fits), main = "Comparisons of All Models")
predictions <- predict(cubist_model, df_eval_transformed)
predictions <- predict(cubist_model, df_model_eval)
imputer<-mice(df_eval, method = "pmm", print = FALSE, seed = 143)
df_eval_imputed <-complete(imputer)
avoid_features = nearZeroVar(df_eval_imputed)
df_model_eval = df_eval_imputed[,-avoid_features]
summary(df_model_train)
predictions <- predict(cubist_model, df_model_eval)
View(df_model_eval)
df_eval$PH_predicted <- round(predictions, 2)
View(df_eval)
temp_file <- tempfile(fileext = ".xlsx")
download.file(url = "https://raw.githubusercontent.com/omerozeren/DATA624/master/Project2/StudentEvaluation.xlsx",
destfile = temp_file,
mode = "wb",
quiet = TRUE)
#load xl from temp
df_eval <- data.frame(readxl::read_excel(temp_file,skip=0))
#  Brand.Code to factor
df_eval$Brand.Code = as.factor(df_eval$Brand.Code)
View(df_eval)
# applying predictions to unimputed dataset
temp_file <- tempfile(fileext = ".xlsx")
download.file(url = "https://raw.githubusercontent.com/omerozeren/DATA624/master/Project2/StudentData.xlsx",
destfile = temp_file,
mode = "wb",
quiet = TRUE)
#load xl from temp
df_train <- data.frame(readxl::read_excel(temp_file,skip=0))
#  Brand.Code to factor
df_train$Brand.Code = as.factor(df_train$Brand.Code)
df_eval$PH <- round(predictions, 2)
setwd("~/GitHub/DATA624/Project2")
write.csv(df_eval, 'eval_PH_predictions.csv', row.names=F)
write.csv(df_eval, 'StudentEvaluation_PH_predictions.csv')
library(readr)
StudentEvaluation_PH_predictions <- read_csv("StudentEvaluation_PH_predictions.csv")
View(StudentEvaluation_PH_predictions)
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
bagControl = bagControl(fit = ctreeBag$fit, predict = ctreeBag$pred, aggregate = ctreeBag$aggregate)
bag_model <- train(PH ~.,
data = train_data, method="bag", bagControl = bagControl,
center = TRUE,
scale = TRUE,
trControl = trainControl("cv", number = 5),
tuneLength = 25)
# Make predictions
bag_pred <- predict(bag_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=bag_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "Bagged-Tree ") %>% rbind(models_test_evaluation)
residPlot(summary(bag_model))
plot(residuals(bag_model))
varImp(bag_model)
varImp(bag_model) %>% as.data.frame() %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall)) +
geom_col(aes(fill = Overall))
varImp(bag_model) %>% as.data.frame() %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
varImp(bag_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
varImp(bag_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
varImp(bag_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
svm_model <- train(PH ~.,
data=train_data,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 25,
trControl = trcontrol)
plot(residuals(svm_model))
varImp(svm_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
cubist_model <- train(PH ~ ., data = train_data, method = "cubist",
trControl = trcontrol,
tuneLength = 25)
# Residual plots
plot(residuals(cubist_model))
varImp(cubist_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
mars_model <- train(PH ~.,
data = train_data,
method = "earth",
tuneLength = 25,
trControl = trcontrol
)
plot(residuals(mars_model))
varImp(mars_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
rf_model <- train(PH ~.,
data = train_data,
method = "rf",
tuneLength = 25,
trControl = trcontrol
)
plot(residuals(rf_model))
varImp(rf_model)  %>%
ggplot(aes(x = reorder(rownames(.), desc(Overall)), y = Overall))
varImp(rf_model)
summary(rf_model)
summary((knnModel))
summary(knn_model)
summary(svm_model)
install.packages("flextable")
kable(describe(df_train)[,-c(1,6,7,13)],
caption = "Descriptive Statistics for All Brand Code",
digit = 2L)
library(tidyverse)
library(kableExtra)
library(xgboost)
library(plyr)
library (e1071)
library(corrplot)
library(ggplot2)
library(tidyr)
library(dplyr)
library(caret)
library(Matrix)
library(writexl)
library(psych)
kable(describe(df_train)[,-c(1,6,7,13)],
caption = "Descriptive Statistics for All Brand Code",
digit = 2L)
describe(df_train)
rf_model
varImp(rf_model)
plot(rf_model)
plot(residuals(rf_model))
plot(residuals(rf_model))
plot(rf_model)
plot(residuals(bag_model))
plot(bag_model)
plot(svm)
# Residual plots
plot(residuals(cubist_model))
plot(cubist_model)
set.seed(123)
trcontrol = trainControl("cv", number = 10, savePredictions=FALSE,  index = createFolds(train_data$PH, 10), verboseIter = FALSE)
svm_model <- train(PH ~.,
data=train_data,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 25,
trControl = trcontrol)
# Make predictions
svm_pred <- predict(svm_model, newdata = test_data)
# Model performance metrics
post_rst<-postResample(obs = test_data$PH, pred=svm_pred)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "SVM") %>% rbind(models_test_evaluation)
# Summary Model
summary(svm_model)
plot(svm)
plot(residuals(svm_model))
plot(svm_model)
plot(cubist_model)
models_test_evaluation <- data.frame(t(post_rst)) %>%
mutate(Model = "Cubist") %>% rbind(models_test_evaluation)
models_test_evaluation
df_train %>%
ggplot(aes(PH, fill = PH > 8.5)) +
geom_histogram(bins = 30) +
theme_bw() +
theme(legend.position = 'center') +
labs(y = 'Count', title = 'PH histogram')
df_train[,-c(1)]  %>%
gather(Variable, Values) %>%
ggplot(aes(x = Values)) +
geom_histogram(alpha = 0.2, col = "black", bins = 15) +
facet_wrap(~ Variable, scales = "free", nrow = 6)
df_train[,-c(1)]  %>%
gather(Variable, Values) %>%
ggplot(aes(x = Values)) +
geom_histogram(alpha = 0.2, col = "black", bins = 15) +
facet_wrap(~ Variable, scales = "free", nrow = 3)
df_train[,-c(1)]  %>%
gather(Variable, Values) %>%
ggplot(aes(x = Values)) +
geom_histogram(alpha = 0.2, col = "black", bins = 15) +
facet_wrap(~ Variable, scales = "free", nrow = 4)
install.packages("glmnet")
install.packages("glmnet")
install.packages("glmnet", dependencies=TRUE)
install.packages("glmnet", repos = "https://cran.rstudio.com")
install.packages("installr")
install.packages("glmnet", repos = "https://cran.rstudio.com")
